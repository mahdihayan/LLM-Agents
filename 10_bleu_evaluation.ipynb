{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrhamedani/LLM-Agents/blob/main/10_bleu_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcSolREOl8Gl"
      },
      "source": [
        "# Evaluating translations with BLEU\n",
        "Models: nllb-200-distilled-600M\n",
        "\n",
        "Colab environment: CPU.\n",
        "\n",
        "Keys:\n",
        "* Bleu Evaluation.\n",
        "* Translation Pipeline.\n",
        "* Google Translator API.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVAkT7wBZjhZ"
      },
      "source": [
        "In this notebook, we will use the BLEU metric to compare the quality of two different approaches for performing translations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C72gH1FT6ANK"
      },
      "outputs": [],
      "source": [
        "!pip install -q googletrans==3.1.0a0\n",
        "!pip install -q evaluate==0.4.2\n",
        "!pip install -q transformers==4.42.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGbFnGU75_Tv"
      },
      "outputs": [],
      "source": [
        "from googletrans import Translator\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDp4f1CQp3hS"
      },
      "outputs": [],
      "source": [
        "#Sentences to Translate.\n",
        "sentences = [\n",
        "    \"In the previous chapters, you've mainly seen how to work with OpenAI models, and you've had a very practical introduction to Hugging Face's open-source models, the use of embeddings, vector databases, and agents.\",\n",
        "    \"These have been very practical chapters in which I've tried to gradually introduce concepts that have allowed you, or at least I hope so, to scale up your knowledge and start creating projects using the current technology stack of large language models.\"\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwvAUtyGbNQ8"
      },
      "outputs": [],
      "source": [
        "#Spanish Translation References.\n",
        "reference_translations = [\n",
        "    [\"En los capítulos anteriores has visto mayoritariamente como trabajar con los modelos de OpenAI, y has tenido una introducción muy práctica a los modelos Open Source de Hugging Face, al uso de embeddings, las bases de datos vectoriales, los agentes.\"],\n",
        "    [\"Han sido capítulos muy prácticos en los que he intentado ir introduciendo conceptos que te han permitido, o eso espero, ir escalando en tus conocimientos y empezar a crear proyectos usando el stack tecnológico actual de los grandes modelos de lenguaje.\"]\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ3Wm2Z9gCTf"
      },
      "source": [
        "We will perform the first translation using the NLLB model, a small model specialized in performing translations, which we will retrieve from Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTO1tNuMrPn-"
      },
      "outputs": [],
      "source": [
        "model_id = \"facebook/nllb-200-distilled-600M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDlw6xChiHf4"
      },
      "source": [
        "When creating the pipeline, we pass the source language and the target language of the translation to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEQT4ae9R2M5"
      },
      "outputs": [],
      "source": [
        "translator = pipeline('translation', model=model, tokenizer=tokenizer,\n",
        "                        src_lang=\"eng_Latn\", tgt_lang=\"spa_Latn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y7br7o0R3mS"
      },
      "outputs": [],
      "source": [
        "translations_nllb = []\n",
        "\n",
        "for text in sentences:\n",
        "  print (\"to translate: \" + text)\n",
        "  translation = \"\"\n",
        "  translation = translator(text)\n",
        "\n",
        "  #Add the summary to summaries list\n",
        "  translations_nllb += translation[0].values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4mfFiNSiZlN"
      },
      "source": [
        "Now we have the translations stored in the list 'translations_nllb'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGS0JZ0GWMe-"
      },
      "outputs": [],
      "source": [
        "translations_nllb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmtO4nZemvRK"
      },
      "source": [
        "##Create Translations with Google Traslator.\n",
        "\n",
        "As a second source for translations, we will use the Google Translator API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNxy4ql9P-ow"
      },
      "outputs": [],
      "source": [
        "translator_google = Translator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAJvQQ_ZQd4i"
      },
      "outputs": [],
      "source": [
        "translations_google = []\n",
        "\n",
        "for text in sentences:\n",
        "  print (\"to translate: \" + text)\n",
        "  translation = \"\"\n",
        "  translation = translator_google.translate(text, dest=\"es\")\n",
        "\n",
        "  #Add the summary to summaries list\n",
        "  translations_google.append(translation.text)\n",
        "  print (translation.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0M4Z5cUqC5z"
      },
      "source": [
        "In this list, we have the translations created by Google."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EkycPnUUL0m"
      },
      "outputs": [],
      "source": [
        "translations_google"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXuT5sl8ptCo"
      },
      "source": [
        "## Evaluate translations with BLEU\n",
        "\n",
        "We will use the BLEU implementation from the Evaluate library by Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdwmVSdfevnX"
      },
      "outputs": [],
      "source": [
        "bleu = evaluate.load('bleu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRAYkTNDp2qg"
      },
      "outputs": [],
      "source": [
        "results_nllb = bleu.compute(predictions=translations_nllb, references=reference_translations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSkAJAfWq0SS"
      },
      "source": [
        "To obtain the metrics, we pass the translated text and the reference text to the BLEU function.\n",
        "\n",
        "Note that the translated text is a list of translations:\n",
        "[\"Translation1\", \"Translation2\"]\n",
        "\n",
        "Whereas the reference texts are a list of lists of text. This allows for providing multiple references per translation:\n",
        "\n",
        "[[\"reference1 Translation1\", \"reference2 Translation1\"],\n",
        "[\"reference2 Translation2\", \"reference2 Translation2\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrvknChXUGPv"
      },
      "outputs": [],
      "source": [
        "results_google = bleu.compute(predictions=translations_google, references=reference_translations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dop9U2ds2YKE"
      },
      "outputs": [],
      "source": [
        "print(results_nllb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "329dBCZxT0F4"
      },
      "outputs": [],
      "source": [
        "print(results_google)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZgXkAq3r4mz"
      },
      "source": [
        "It appears that the translation performed by the Google API is significantly better than the one performed by the NLLB model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}